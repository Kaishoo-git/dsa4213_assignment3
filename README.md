# Fine-tuning  of LLMs

``` bash
pip install -r requirements.txt
python main.py
```

This is a project exploring the effectiveness of various fine-tuning strategies on pre-trained transformer models.
For benchmarking, we would be using [**SQuAD Dataset**](https://rajpurkar.github.io/SQuAD-explorer/) dataset.
Metrics-wise, we would be comparing the models in question-answering tasks. Specifically, F1-score and BERTSCORE.

For results of this project, please refer to [**Report**](./report.md)